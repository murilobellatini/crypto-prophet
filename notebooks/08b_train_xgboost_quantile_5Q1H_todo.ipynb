{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155810e7",
   "metadata": {},
   "source": [
    "# CryptoProphet\n",
    "## Notebook's Goal\n",
    "> To test the hypothesis that tweets of influencers have an effect on the price of crypto, we take the tweets and try to solve a classicfication problem using XGBoost. For this approach we have 2 parameters we tried out, namely the number of classes we want to predict and the time of the future price prediction. In this notebook 5 classes were used namely: **'STONG_DECREASE', 'DECREASE', 'NEUTRAL', 'INCREASE', 'STRONG_INCREASE'**. And the time of the price prediction is **1 hour** after the tweet was published. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3f4bfef-ba9d-4bf7-8064-25de54cce75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hohih\\anaconda3\\envs\\makeathon\\lib\\site-packages\\ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# imports custom packages\n",
    "\n",
    "from src.paths import LOCAL_RAW_DATA_PATH, LOCAL_PROCESSED_DATA_PATH, LOCAL_MODELS_PATH\n",
    "\n",
    "# imports official packages\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "from collections import OrderedDict\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import skew\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# imports dataset with tweets in form of a panda dataframe\n",
    "df_path = LOCAL_PROCESSED_DATA_PATH / 'pretrain_dataset_20211013.pkl'\n",
    "df = pd.read_pickle(df_path)\n",
    "tgt_vars = [c for c in df.columns if '_change_' in str(c)]\n",
    "\n",
    "# some informations are unnnecessary so we drop unused columns of the dataframe\n",
    "\n",
    "drop_cols = ['created_at', 'created_at_trunc_h', 'id_str',\n",
    "             'full_text', 'user_screen_name',\n",
    "             'ma_120_periods', 'ma_720_periods'] + tgt_vars\n",
    "X_cols = [c for c in df.columns if c not in drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f8dd87-1ce1-44bf-bcba-1227474336e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Interval(-0.136, -0.00702, closed='right'): 'STONG_DECREASE_Q1',\n",
       " Interval(-0.00702, -0.00158, closed='right'): 'DECREASE_Q2',\n",
       " Interval(-0.00158, 0.00193, closed='right'): 'NEUTRAL_Q3',\n",
       " Interval(0.00193, 0.00773, closed='right'): 'INCREASE_Q4',\n",
       " Interval(0.00773, 0.146, closed='right'): 'STRONG_INCREASE_Q5'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We extract quantiles in order to form 5 classes based on, if a value lies in a certain range or not\n",
    "df['close_change_2periods_perc_5Q'] = pd.qcut(df['close_change_2periods_perc'], q=5)\n",
    "cc2pp5Q_to_hr = {}\n",
    "scale = ['STONG_DECREASE', 'DECREASE', 'NEUTRAL', 'INCREASE', 'STRONG_INCREASE']\n",
    "for i, v in enumerate(df['close_change_2periods_perc_5Q'].unique().sort_values()):\n",
    "    cc2pp5Q_to_hr[v] = scale[i] + f'_Q{i+1}' \n",
    "cc2pp5Q_to_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e572609c-5fad-4de8-a885-3c055ec4ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map quantiles to human readable form, basicallly a text 'STONG_DECREASE', 'DECREASE', ...\n",
    "df['close_change_2periods_perc_5Q_HR'] = df['close_change_2periods_perc_5Q'].map(cc2pp5Q_to_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45abf28d-3f70-48e8-a5cd-4ceda01b919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[X_cols]\n",
    "y = df['close_change_2periods_perc_5Q_HR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d33130-db92-47b0-b8e1-597ac9405dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check on null values\n",
    "X.isna().sum().sum(), y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2997dc3-bd21-4d40-b629-302fc3b4d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits dataset into train and test datasets. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d44a7c-c366-40a9-9fba-c459341ec020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73656, 779) (18415, 779)\n",
      "(73656,) (18415,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check on resulting shapes\n",
    "print(X_train.shape,  X_test.shape)\n",
    "print(y_train.shape,  y_test.shape)\n",
    "df.shape[0] == X_train.shape[0] + X_test.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fced42c-4379-41fc-91b7-124053b2a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost.XGBClassifier\n",
    "# xgboost.XGBRFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6037d6-dd72-42e9-ac89-a682c214f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize and fits model using XGBoost\n",
    "xgboost.set_config(**{'use_rmm': False, 'verbosity': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87634de9-16b9-4a38-8707-de5936763363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hohih\\anaconda3\\envs\\makeathon\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "model = xgboost.XGBRFClassifier(**{\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1.5,\n",
    "    'n_estimators': 1200,\n",
    "    'reg_alpha': 0.75,\n",
    "    'reg_lambda': 0.45,\n",
    "    'seed': seed,\n",
    "    'subsample': 0.9\n",
    "}) \n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model to pickle file\n",
    "with open(LOCAL_MODELS_PATH / 'xgboost_20211014_XGBRFClassifier.pkl', mode='wb') as fp:\n",
    "    pickle.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cad4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408b167-2f44-4100-8cea-adc09004d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows overall score of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145d929-cf68-4c80-9460-58d365f73c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots results in a confusion matrix to try to evalute the modelv\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(model, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923db71c-bb09-4469-ae2f-6bb6dee2ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b37a1d-d7eb-4a86-8722-bacaa926a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062cb20-8f41-4aa5-825e-672fce84c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fe857-ee96-40f9-9b82-cdc2215c04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports data\n",
    "with open(LOCAL_MODELS_PATH / 'user_label_encoder.pkl', 'rb') as fp:\n",
    "    user_le = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d821c-9efb-4604-9b9a-2716a7eb82bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c6051-8d09-4566-a2fc-88334934b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define plot function\n",
    "def plot_stats(model, X, y, test_name=None):\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    score = model.score(X, y)  \n",
    "    print(f\"{test_name} - R^2 score: \", score)\n",
    "\n",
    "    plot_confusion_matrix(model, X, y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd15b3-821e-43ab-8b09-dc3fd73ce242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints score ordered by influencers accuracy\n",
    "user2score = []\n",
    "for u in X_train.user_feat.unique():\n",
    "    mask = X.user_feat == u\n",
    "    user_screen_name = user_le.inverse_transform([u])[0]\n",
    "    stats ={\n",
    "        'user_label': u,\n",
    "        'user_screen_name': user_screen_name,\n",
    "        'accuracy': model.score(X[mask], y[mask]),\n",
    "        'tweet_count': mask.sum()}\n",
    "    user2score.append(stats)\n",
    "user2score = pd.DataFrame(user2score).sort_values('accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa10efe-3f7c-4c3e-9c8e-8ead316be6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180cd0c5-7431-46e7-8c5f-b93749090c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of prediction vs ground truth for each infleuncer separetly\n",
    "for u in X_train.user_feat.unique():\n",
    "    mask = X_train.user_feat == u\n",
    "    mask_test = X_test.user_feat == u\n",
    "    user_screen_name = user_le.inverse_transform([u])[0]\n",
    "    print(f\"{user_screen_name} - {mask.sum() + mask_test.sum()} tweets\")\n",
    "\n",
    "    try:\n",
    "        plot_stats(model, X_train[mask], y_train[mask], test_name=f\"{user_screen_name} - full data\")\n",
    "        plot_stats(model, X_test[mask_test], y_test[mask_test], test_name=f\"{user_screen_name} - train data\")\n",
    "    except Exception as e:\n",
    "        print(f'error {e}')\n",
    "        \n",
    "    print(20*'=')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25a8ba-b246-407e-92e4-6b770132f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X_train, y_train ,cv=10)\n",
    "print(\"Cross Val Score: \", score)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "kf_cv_scores = cross_val_score(model, X_train, y_train, cv=kfold )\n",
    "print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613f9f7-2725-4f7a-a9d1-258d6ffc4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\n",
    "#     'colsample_bytree': [0.3, 0.8], #0.3 to 0.8\n",
    "#     'gamma': [0], # 0, 1, 5                 \n",
    "#     'learning_rate': [0.01, 0.1], # 0.1 and 0.01 #\n",
    "#     'max_depth': [1,5],\n",
    "#     'min_child_weight': [1.5],\n",
    "#     'n_estimators': [1200], #  80-200 if the size of data is high (of the order of millions), 800-1200 is if it is medium-low                                                                    \n",
    "#     'reg_alpha': [0.75],\n",
    "#     'reg_lambda': [0.45],\n",
    "#     'subsample': [0.9,2], #  0.8 and 1\n",
    "#     'seed': [seed]\n",
    "# }\n",
    "# gs = GridSearchCV(xgbr, parameters)\n",
    "# gs.fit(X_train,y_train)\n",
    "# y_pred = gs.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b3c1c-e886-4d01-a526-17f0a95f4770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52db46-ecb9-42dd-9a59-e39e208fe4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgboost.XGBRegressor(\n",
    "#                  colsample_bytree=0.5, #0.3 to 0.8\n",
    "#                  gamma=0, # 0, 1, 5                 \n",
    "#                  learning_rate=0.07, # 0.1 and 0.01 #\n",
    "#                  max_depth=3,\n",
    "#                  min_child_weight=1.5,\n",
    "#                  n_estimators=1200, #  80-200 if the size of data is high (of the order of millions), 800-1200 is if it is medium-low                                                                    \n",
    "#                  reg_alpha=0.75,\n",
    "#                  reg_lambda=0.45,\n",
    "#                  subsample=0.8, #  0.8 and 1\n",
    "#                  seed=seed) \n",
    "\n",
    "# model.fit(X_train,y_train)\n",
    "\n",
    "# score = model.score(X_train, y_train)  \n",
    "# print(\"Training score: \", score)\n",
    "\n",
    "# y_pred = model.predict(X_train)\n",
    "# x_ax = range(len(y_train))\n",
    "# plt.plot(x_ax, y_train, label=\"original\")\n",
    "# plt.plot(x_ax, y_pred, label=\"predicted\")\n",
    "# plt.title(\"XGBoostRegressor test and predicted data\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758dc5c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "> Model overall contains too much noise, however some influencer show promissing results. Mots of the results are over 30% so the model performs better than a random classifier.\n",
    "> (eg. PeterMcCormack with accuracy of 0.487963).\n",
    ">Other combinations of classes/prediction time perform better.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ffb28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
